{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['sentiment', 'content']]\n",
    "labels = data.sentiment \n",
    "texts = data.content\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "texts = texts.apply(lambda x: x.lower())\n",
    "texts = texts.apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tiffanylue know listenin bad habit earlier sta...\n",
       "1               layin n bed headache ughhhhwaitin call\n",
       "2                        funeral ceremonygloomy friday\n",
       "3                              wants hang friends soon\n",
       "4    dannycastillo want trade someone houston ticke...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english')\n",
    "texts=texts.apply(lambda sen:\" \".join(x for x in sen.split() if x not in stop))\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "MAX_NB_WORDS = 20000\n",
    "MAX_SEQUENCE_LENGTH=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53145 unique tokens.\n",
      "0    tiffanylue know listenin bad habit earlier sta...\n",
      "1               layin n bed headache ughhhhwaitin call\n",
      "2                        funeral ceremonygloomy friday\n",
      "3                              wants hang friends soon\n",
      "4    dannycastillo want trade someone houston ticke...\n",
      "5    repinging ghostridah14 didnt go prom bc bf did...\n",
      "6    sleep im thinking old friend want hes married ...\n",
      "7                                hmmm httpwwwdjherocom\n",
      "8                         charviray charlene love miss\n",
      "9                       kelcouch im sorry least friday\n",
      "Name: content, dtype: object\n",
      "Shape of data tensor: (40000, 30)\n",
      "Shape of label tensor: (40000, 13)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "X = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print(texts[:10])\n",
    "Y = data['sentiment']\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "Y=le.transform(Y) \n",
    "labels = to_categorical(np.asarray(Y))\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26800, 30) (26800, 13)\n",
      "(13200, 30) (13200, 13)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)\n",
    "\n",
    "x_val = X_train[:5000]\n",
    "partial_x_train = X_train[5000:]\n",
    "y_val = Y_train[:5000]\n",
    "partial_y_train = Y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1917494 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from keras import models \n",
    "from keras import layers \n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.42B.300d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models \n",
    "from keras import layers \n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "EMBEDDING_DIM = 300 \n",
    "num_words = min(MAX_NB_WORDS, len(word_index)) \n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\lily2\\pycharmprojects\\rong1\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\lily2\\pycharmprojects\\rong1\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 300)           6000000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               389648    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                2561      \n",
      "=================================================================\n",
      "Total params: 6,392,209\n",
      "Trainable params: 392,209\n",
      "Non-trainable params: 6,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 300\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(LSTM(196, dropout=0.25, recurrent_dropout=0.2))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(Dense(13,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21800 samples, validate on 5000 samples\n",
      "Epoch 1/15\n",
      "21800/21800 [==============================] - 61s 3ms/step - loss: 1.8391 - acc: 0.3672 - val_loss: 1.8461 - val_acc: 0.3720\n",
      "Epoch 2/15\n",
      "21800/21800 [==============================] - 68s 3ms/step - loss: 1.8238 - acc: 0.3743 - val_loss: 1.8413 - val_acc: 0.3662\n",
      "Epoch 3/15\n",
      "21800/21800 [==============================] - 63s 3ms/step - loss: 1.8175 - acc: 0.3753 - val_loss: 1.8427 - val_acc: 0.3698\n",
      "Epoch 4/15\n",
      "21800/21800 [==============================] - 62s 3ms/step - loss: 1.8172 - acc: 0.3751 - val_loss: 1.8462 - val_acc: 0.3710\n",
      "Epoch 5/15\n",
      "21800/21800 [==============================] - 61s 3ms/step - loss: 1.8045 - acc: 0.3842 - val_loss: 1.8426 - val_acc: 0.3718\n",
      "Epoch 6/15\n",
      "21800/21800 [==============================] - 59s 3ms/step - loss: 1.8026 - acc: 0.3828 - val_loss: 1.8431 - val_acc: 0.3712\n",
      "Epoch 7/15\n",
      "21800/21800 [==============================] - 61s 3ms/step - loss: 1.7927 - acc: 0.3826 - val_loss: 1.8463 - val_acc: 0.3674\n",
      "Epoch 8/15\n",
      "21800/21800 [==============================] - 62s 3ms/step - loss: 1.7824 - acc: 0.3903 - val_loss: 1.8468 - val_acc: 0.3710\n",
      "Epoch 9/15\n",
      "21800/21800 [==============================] - 60s 3ms/step - loss: 1.7828 - acc: 0.3841 - val_loss: 1.8563 - val_acc: 0.3682\n",
      "Epoch 10/15\n",
      "21800/21800 [==============================] - 64s 3ms/step - loss: 1.7696 - acc: 0.3926 - val_loss: 1.8491 - val_acc: 0.3714\n",
      "Epoch 11/15\n",
      "21800/21800 [==============================] - 64s 3ms/step - loss: 1.7609 - acc: 0.3943 - val_loss: 1.8520 - val_acc: 0.3666\n",
      "Epoch 12/15\n",
      "21800/21800 [==============================] - 67s 3ms/step - loss: 1.7625 - acc: 0.3975 - val_loss: 1.8518 - val_acc: 0.3686\n",
      "Epoch 13/15\n",
      "21800/21800 [==============================] - 67s 3ms/step - loss: 1.7489 - acc: 0.4001 - val_loss: 1.8612 - val_acc: 0.3678\n",
      "Epoch 14/15\n",
      "21800/21800 [==============================] - 65s 3ms/step - loss: 1.7471 - acc: 0.3944 - val_loss: 1.8574 - val_acc: 0.3690\n",
      "Epoch 15/15\n",
      "21800/21800 [==============================] - 65s 3ms/step - loss: 1.7403 - acc: 0.3955 - val_loss: 1.8642 - val_acc: 0.3704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a46f0dd68>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(partial_x_train, partial_y_train,\n",
    "          batch_size=128,\n",
    "          epochs=15,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 1.87\n",
      "acc: 0.37\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(X_test, Y_test, verbose = 2)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
